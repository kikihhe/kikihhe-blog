---
title: cAdvisor
date: 2025-03-06 16:40:06
permalink: /pages/4769d6/
---
## 1. 简述

cAdvisor 是 Google 开源的一款用于展示和分析容器运行状态的可视化工具。通过在主机上运行 CAdvisor，用户可以轻松的获取到当前主机上容器的运行统计信息，并以图表的形式向用户展示。

cAdvisor 可以对节点机器上的资源及容器进行实时监控和性能数据采集，包括 `CPU使用情况、内存使用情况、网络吞吐量及文件系统使用情况`。

cAdvisor 的数据采集分为两个部分 machineInfo 和 containerInfo ：

![](https://typorehwf.oss-cn-chengdu.aliyuncs.com/13618762-da3640a5a6732e5a.png)

源码位置 ：https://github.com/google/cadvisor.git

## 2. Manager

cAdvisor 中最重要的组件是 Manager，cmd/cAdvisor.go 中启动 cAdvisor 的逻辑也主要是创建了一个 Manager 并启动它。

```go
// manager/manager.go
// The Manager interface defines operations for starting a manager and getting container and machine information.
type Manager interface {
	// Start the manager. Calling other manager methods before this returns
	// may produce undefined behavior.
	// 启动 cAdvisor Container Manager
	Start() error

	// Stops the manager.
	Stop() error

	//  information about a container.
	// 获取指定容器的信息
	GetContainerInfo(containerName string, query *info.ContainerInfoRequest) (*info.ContainerInfo, error)

	// Get V2 information about a container.
	// Recursive (subcontainer) requests are best-effort, and may return a partial result alongside an
	// error in the partial failure case.
	GetContainerInfoV2(containerName string, options v2.RequestOptions) (map[string]v2.ContainerInfo, error)

	// Get information about all subcontainers of the specified container (includes self).
	// 获取容器的子容器信息
	SubcontainersInfo(containerName string, query *info.ContainerInfoRequest) ([]*info.ContainerInfo, error)

	// Gets all the Docker containers. Return is a map from full container name to ContainerInfo.
	// 获取所有的 docker 容器信息
	AllDockerContainers(query *info.ContainerInfoRequest) (map[string]info.ContainerInfo, error)

	// Gets information about a specific Docker container. The specified name is within the Docker namespace.
	// 获取指定的 docker 容器信息
	DockerContainer(dockerName string, query *info.ContainerInfoRequest) (info.ContainerInfo, error)

	PodmanContainer(containerName string, query *info.ContainerInfoRequest) (info.ContainerInfo, error)

	// Gets spec for all containers based on request options.
	// 获取指定的容器 spec
	GetContainerSpec(containerName string, options v2.RequestOptions) (map[string]v2.ContainerSpec, error)

	// Gets summary stats for all containers based on request options.
	// 基于请求选项获取所有容器的摘要统计信息
	GetDerivedStats(containerName string, options v2.RequestOptions) (map[string]v2.DerivedStats, error)

	// Get info for all requested containers based on the request options.
	// 根据请求选项获取容器的详细信息
	GetRequestedContainersInfo(containerName string, options v2.RequestOptions) (map[string]*info.ContainerInfo, error)

	// Returns true if the named container exists.
	// 容器是否存在
	Exists(containerName string) bool

	// Get information about the machine.
	// 获取宿主机信息
	GetMachineInfo() (*info.MachineInfo, error)

	// Get version information about different components we depend on.
	// 获取我们依赖的不同组件的版本信息
	GetVersionInfo() (*info.VersionInfo, error)

	// GetFsInfoByFsUUID returns the information of the device having the
	// specified filesystem uuid. If no such device with the UUID exists, this
	// function will return the fs.ErrNoSuchDevice error.
	// 返回具有指定文件系统 uuid 的设备的信息。如果不存在具有 UUID 的此类设备，则此函数将返回 fs.ErrNoSuchDevice 错误。
	GetFsInfoByFsUUID(uuid string) (v2.FsInfo, error)

	// Get filesystem information for the filesystem that contains the given directory
	// 获取包含指定目录的文件系统的信息
	GetDirFsInfo(dir string) (v2.FsInfo, error)

	// Get filesystem information for a given label.
	// Returns information for all global filesystems if label is empty.
	// 获取给定标签的文件系统信息，如果标签为空，获取全部文件系统的信息
	GetFsInfo(label string) ([]v2.FsInfo, error)

	// Get ps output for a container.
	// 获取容器的进程列表
	GetProcessList(containerName string, options v2.RequestOptions) ([]v2.ProcessInfo, error)

	// Get events streamed through passedChannel that fit the request.
	// 获取通过 passedChannel 传输的事件
	WatchForEvents(request *events.Request) (*events.EventChannel, error)

	// Get past events that have been detected and that fit the request.
	// 获取过期事件
	GetPastEvents(request *events.Request) ([]*info.Event, error)

	// 关闭 eventChannel
	CloseEventChannel(watchID int)

	// Returns debugging information. Map of lines per category.
	// 返回调试信息
	DebugInfo() map[string][]string

	AllPodmanContainers(c *info.ContainerInfoRequest) (map[string]info.ContainerInfo, error)
}
```

Manager 提供了两个非常重要的方法 GetContainerInfo、GetMachineInfo 也就是 cAdvisor 的核心功能。

Manager 的实现是 manager ：

```go
// manager 是 Manager 接口的实现类，包含 cAdvisor 运行所需的各种信息
type manager struct {

	// 当前受到监控的容器全部存在于这个 map 中
	// containerData 中包括了对容器的各种操作方式和容器相关信息
    // GetContainerInfo() 获取的就是这个字段
	containers     map[namespacedContainerName]*containerData
	containersLock sync.RWMutex

	// 缓存在内存中的数据，主要是容器的相关信息
	memoryCache *memory.InMemoryCache

	// FsInfo 用于获取主机文件系统信息，及相关的设备、挂载点等信息。
	fsInfo fs.FsInfo

	// 用于获取宿主机的 system信息
	// 如 cpu 、网络设备
	sysFs sysfs.SysFs

	machineMu sync.RWMutex // protects machineInfo

	// 宿主机信息，cpu memory network system 磁盘信息 云供应商信息 等等
    // 通过 sysFs 和 FsInfo 合力可以获取 machineInfo
    // GetMachineInfo() 就是返回这个变量
	machineInfo info.MachineInfo

	// 用于存放退出信号的 channel，manager 关闭的时候会这个数组的 chan 发送退出信号
	quitChannels []chan error

	// cadvisor 本身（如果 cadvisor 运行在容器中）
	cadvisorContainer string

	// 是否在 host 的 namespace
	inHostNamespace bool

	// 事件管理器
	eventHandler events.EventManager

	// manager 启动时间
	startupTime time.Time

	// 在内存中保留数据的时间，也就是下一次开始收集数据并更新内存的时间
	maxHousekeepingInterval  time.Duration
	allowDynamicHousekeeping bool

	// 需要采集的指标
	includedMetrics container.MetricSet

	// container 监听器，用于监听当前机器上的容器的 cd 事件，将事件放入 eventsChannel 中
	containerWatchers []watcher.ContainerWatcher

	// 事件 channel, 本机的容器发生新增/删除事件时，监听器会将事件放入该 channel 中
	eventsChannel chan watcher.ContainerEvent

	// 收集器的客户端
	collectorHTTPClient *http.Client

	perfManager stats.Manager

	resctrlManager resctrl.Manager

	// List of raw container cgroup path prefix whitelist.
	// raw 容器 cgroup 路径前缀白名单
	rawContainerCgroupPathPrefixWhiteList []string

	// List of container env prefix whitelist, the matched container envs would be collected into metrics as extra labels.
	containerEnvMetadataWhiteList []string
}
```

manager 包含了整个 cAdvisor 的核心组件，接下来将会介绍 manager 内部的各个字段

### 2.1 SysFs

SysFs 用于获取操作系统底层的一些信息，比如 NUMA、网络设备、CPU 缓存等等

```go
// SysFs 定义了一系列方法用于获取操作系统底层的一些信息
type SysFs interface {

	// 获取系统中所有NUMA节点的路径
    // NUMA: 非统一内存访问
	GetNodesPaths() ([]string, error)

	// 获取所有的 CPU 的路径
	GetCPUsPaths(cpusPath string) ([]string, error)

	// Get physical core id for specified CPU
	GetCoreID(coreIDFilePath string) (string, error)

	// Get physical package id for specified CPU
	GetCPUPhysicalPackageID(cpuPath string) (string, error)

	// Get book id for specified CPU
	GetBookID(cpuPath string) (string, error)

	// Get drawer id for specified CPU
	GetDrawerID(cpuPath string) (string, error)

	// 获取某个 NUMA 节点的内存信息
	GetMemInfo(nodeDir string) (string, error)

	// Get hugepages from specified directory
	GetHugePagesInfo(hugePagesDirectory string) ([]os.FileInfo, error)

	// Get hugepage_nr from specified directory
	GetHugePagesNr(hugePagesDirectory string, hugePageName string) (string, error)

	// 获取所有可用的块设备的目录信息，访问的是 /sys/block 目录
	GetBlockDevices() ([]os.FileInfo, error)

	// 获取指定块设备的大小，访问的是 /sys/block/${device-name}/dev 文件
	GetBlockDeviceSize(string) (string, error)

	// 获取指定块设备的调度器类型，访问的是 /sys/block/${device-name}/queue/scheduler 文件
	GetBlockDeviceScheduler(string) (string, error)

	// 获取块设备的 major:minor 数字字符串，访问的是 /sys/block/${device-name}/size 文件
	GetBlockDeviceNumbers(string) (string, error)

	// Is the device "hidden" (meaning will not have a device handle)
	// This is the case with native nvme multipathing.
	IsBlockDeviceHidden(string) (bool, error)

	// 获取所有的网络设备信息，访问的是 /sys/class/net 目录
	GetNetworkDevices() ([]os.FileInfo, error)
	// 获取指定网络设备的 MAC 地址信息，访问的是 /sys/class/net/${device-name}/address 文件
	GetNetworkAddress(string) (string, error)
	// 获取指定网络设备的 MTU（最大传输单元（MTU）指通过联网设备可以接收的最大数据包的值），
	GetNetworkMtu(string) (string, error)
	// 获取网络设备的网速信息，访问的是 /sys/class/net/${device-name}/speed 文件
	GetNetworkSpeed(string) (string, error)
	// 获取网络设备的统计信息，访问的是/sys/class/net/${device-name}/statistics 文件
	GetNetworkStatValue(dev string, stat string) (uint64, error)

	// 获取 cpu 的高速缓存目录信息，访问的是 /sys/devices/system/cpu/cpu${cpu-id}/cache 目录
	GetCaches(id int) ([]os.FileInfo, error)

	// 获取指定 cpu 的高速缓存信息，包括 size、level、type、cpu数量
	// 访问的是 /sys/devices/system/cpu/cpu${cpu-id}/cache/${cache} 文件
	GetCacheInfo(cpu int, cache string) (CacheInfo, error)

	// 获取系统的 UUID
	GetSystemUUID() (string, error)

	// GetDistances returns distance array
	GetDistances(string) (string, error)

	// IsCPUOnline determines if CPU status from kernel hotplug machanism standpoint.
	// See: https://www.kernel.org/doc/html/latest/core-api/cpu_hotplug.html
	IsCPUOnline(dir string) bool
}
```

- NUMA ：全称 非统一内存访问，属于计算机架构的一种设计，主要用于多处理器系统。早期的 SMP（对称多处理）架构中，所有 CPU 共享同一内存总线，当CPU 数量增加时，总线会成为瓶颈。NUMA 通过将内存和 CPU 分组，每个节点内的内存访问更快，跨节点访问较慢，从而提升性能。

  每一个分组称其为 NUMA 节点（node），所有节点位于 `/sys/devices/system/node` 目录下，每一个 node 包含一组cpu核心、它们使用的内存、IO控制器

它的实现类为 realSysFs

```go
type realSysFs struct {
    cpuPath string
}

func NewRealSysFs() SysFs {
	return &realSysFs{
		cpuPath: "/sys/devices/system/cpu",
	}
}
```



### 2.2 FsInfo

FsInfo 用于获取主机文件系统信息，及相关的设备、挂载点等信息。

```go
// FsInfo 用于获取主机文件系统信息，及相关的设备、挂载点等信息。
type FsInfo interface {
	// 返回主机上所有ext2、ext3和ext4文件系统的容量和可用空间（以字节为单位）。
	GetGlobalFsInfo() ([]Fs, error)

	// 返回传递的挂载点集合的容量和可用空间（以字节为单位）。
	GetFsInfoForPath(mountSet map[string]struct{}) ([]Fs, error)

	// 返回指定目录的使用情况
	GetDirUsage(dir string) (UsageInfo, error)

	// 返回指定文件系统uuid关联的设备的信息。如果不存在此类设备，则此函数将返回ErrNoSuchDevice错误。
	GetDeviceInfoByFsUUID(uuid string) (*DeviceInfo, error)

	// 返回“dir”所在文件系统的块设备信息。
	GetDirFsDevice(dir string) (*DeviceInfo, error)

	// 返回与特定标签关联的设备名称。
	GetDeviceForLabel(label string) (string, error)

	// 返回与特定设备名称关联的所有标签。
	GetLabelsForDevice(device string) ([]string, error)

	// 返回与特定设备关联的挂载点。
	GetMountpointForDevice(device string) (string, error)
}
```

RealFsInfo 是 FsInfo 的实现

```go
type RealFsInfo struct {
    // 从块设备路径映射到分区信息。
    partitions map[string]partition
    // 从标签映射到块设备路径。
    // 标签是自动检测到的特定于意图的标签。
    labels map[string]string
    // 从挂载点映射到挂载信息。
    mounts map[string]mount.Info
    // devicemapper 客户端
    dmsetup devicemapper.DmsetupClient
    // fsUUIDToDeviceName 是从文件系统UUID到其设备名称的映射。
    fsUUIDToDeviceName map[string]string
}
```



### 2.3 MachineInfo

MachineInfo 用于记录宿主机的各项信息，GetMachineInfo() 获取的就是这个 Model

```go
// MachineInfo 记录宿主机的各项信息
// 通过 sysfs, fsInfo 配合可以得到，具体参见 machine/info.go/Info(sysfs, fsInfo, inHostNamespace)
type MachineInfo struct {

	// The time of this information point.
	// 当前信息的采集时间点
	Timestamp time.Time `json:"timestamp"`

	// Vendor id of CPU
	CPUVendorID string `json:"vendor_id"`

	// The number of cores in this machine.
	// 机器上 CPU 逻辑核心数量

	NumCores int `json:"num_cores"`

	// The number of physical cores in this machine.
	// 机器上 CPU 物理核心数量
	NumPhysicalCores int `json:"num_physical_cores"`

	// The number of cpu sockets in this machine.
	// CPU 插槽数量
	NumSockets int `json:"num_sockets"`

	// Maximum clock speed for the cores, in KHz.
	// 最大 CPU 时钟频率
	CpuFrequency uint64 `json:"cpu_frequency_khz"`

	// The amount of memory (in bytes) in this machine
	// 内存容量（字节）
	MemoryCapacity uint64 `json:"memory_capacity"`

	// The amount of swap (in bytes) in this machine
	//
	SwapCapacity uint64 `json:"swap_capacity"`

	// Memory capacity and number of DIMMs by memory type
	// 按内存类型划分的内存信息
	MemoryByType map[string]*MemoryInfo `json:"memory_by_type"`

	// 非易失性内存模块的信息
	NVMInfo NVMInfo `json:"nvm"`

	// HugePages on this machine.
	// 大页信息
	HugePages []HugePagesInfo `json:"hugepages"`

	// The machine id
	// 机器 id
	MachineID string `json:"machine_id"`

	// The system uuid
	// 系统 UUID
	SystemUUID string `json:"system_uuid"`

	// The boot id
	BootID string `json:"boot_id"`

	// Filesystems on this machine.
	// 本机文件系统信息
	Filesystems []FsInfo `json:"filesystems"`

	// Disk map
	// 本机磁盘信息
	DiskMap map[string]DiskInfo `json:"disk_map"`

	// Network devices
	// 网络设备信息
	NetworkDevices []NetInfo `json:"network_devices"`

	// Machine Topology
	// Describes cpu/memory layout and hierarchy.
	// 机器拓扑，描述 cpu/内存布局 和 层次结构
	Topology []Node `json:"topology"`

	// Cloud provider the machine belongs to.
	// 本机的云供应商
	CloudProvider CloudProvider `json:"cloud_provider"`

	// Type of cloud instance (e.g. GCE standard) the machine is.
	// 机器的云实例类型，比如 GCE 标准
	InstanceType InstanceType `json:"instance_type"`

	// ID of cloud instance (e.g. instance-1) given to it by the cloud provider.
	// 云供应商提供给本机的云实例id
	InstanceID InstanceID `json:"instance_id"`
}
```



### 2.4 ContainerWatcher

ContainerWatcher 用于监听当前系统中容器的新增或者删除事件

```go
// container 监听器，用于监听当前机器上的容器的 crud 事件
type ContainerWatcher interface {
	
	// 监听所有子容器的新增或删除事件，并将事件写入到 ContainerEvent 通道中
	Start(events chan ContainerEvent) error

	// Stops watching for subcontainer changes.
	Stop() error
}


type ContainerEvent struct {

	EventType ContainerEventType

	// 发生事件的容器的名称
	Name string

	// 事件来源
	WatchSource ContainerWatchSource
}

// 事件类型，新增/删除
type ContainerEventType int
const (
	ContainerAdd ContainerEventType = iota
	ContainerDelete
)
```

ContainerWatcher 的实现类为 rawContainerWatcher，它会通过 INotify 来监听 cgroups 的目录，当出现新增/删除 事件时发出 ContainerEvent

```go
// rawContainerWatcher 在 manager 启动的时候通过遍历 cgroups 子系统目录，完成机器上容器列表的初始化，并且设置 InotifyWatcher
// 从而监听所有 cgroup 子目录的变化情况，并抛出相关事件，然后这些事件放入 eventChannel 中交给消费者处理
// 还会定期扫描容器列表，防止出现遗漏
type rawContainerWatcher struct {
    // cgroup目录树的根目录
	cgroupPaths map[string]string

	// 目录监听器
	watcher *common.InotifyWatcher

	// Signal for watcher thread to stop.
	stopWatcher chan error
}
```

创建 rawContainerWatcher 时需要提供监控的指标，因为要通过监控的指标确定访问哪个 cgroups 目录

```go
// includedMetrics: 监控指标，cpu memory...
func NewRawContainerWatcher(includedMetrics container.MetricSet) (watcher.ContainerWatcher, error) {
	cgroupSubsystems, err := libcontainer.GetCgroupSubsystems(includedMetrics)
	if err != nil {
		return nil, fmt.Errorf("failed to get cgroup subsystems: %v", err)
	}
	if len(cgroupSubsystems) == 0 {
		return nil, fmt.Errorf("failed to find supported cgroup mounts for the raw factory")
	}

	watcher, err := common.NewInotifyWatcher()
	if err != nil {
		return nil, err
	}

	rawWatcher := &rawContainerWatcher{
		cgroupPaths: cgroupSubsystems,
		watcher:     watcher,
		stopWatcher: make(chan error),
	}

	return rawWatcher, nil
}
```

启动 ContainerWatcher 会将 cgroups 加入到 INotify 的监控之中，当出现目录的 New/Delete 时将事件放入 eventChannel 中

Manager 在启动时会调用这个方法来启动对于容器的监听，这里要注意入参的 eventChannel

```go
func (w *rawContainerWatcher) Start(events chan watcher.ContainerEvent) error {
	// 将 cgroups 目录绑定到 InNotify
	watched := make([]string, 0)
	for _, cgroupPath := range w.cgroupPaths {
		_, err := w.watchDirectory(events, cgroupPath, "/")
		if err != nil {
			for _, watchedCgroupPath := range watched {
				_, removeErr := w.watcher.RemoveWatch("/", watchedCgroupPath)
				if removeErr != nil {
					klog.Warningf("Failed to remove inotify watch for %q with error: %v", watchedCgroupPath, removeErr)
				}
			}
			return err
		}
		watched = append(watched, cgroupPath)
	}

	go func() {
		for {
			select {
            // INotify 检测到 cgroups 的目录出现事件时，将其转化为具体的容器事件，发送到 eventChannel 中
			case event := <-w.watcher.Event():
				err := w.processEvent(event, events)
				if err != nil {
					klog.Warningf("Error while processing event (%+v): %v", event, err)
				}
                
			case err := <-w.watcher.Error():
				klog.Warningf("Error while watching %q: %v", "/", err)
                
			case <-w.stopWatcher:
				err := w.watcher.Close()
				if err == nil {
					w.stopWatcher <- err
					return
				}
			}
		}
	}()

	return nil
}
```

watcher.processEvent 无非就是将 INotify 的事件转化为容器事件 containerEvent 然后放到 eventChannel 中

```go
func (w *rawContainerWatcher) processEvent(event *inotify.Event, events chan watcher.ContainerEvent) error {
	 
	var eventType watcher.ContainerEventType
	switch {
	case (event.Mask & inotify.InCreate) > 0:
		eventType = watcher.ContainerAdd
	case (event.Mask & inotify.InDelete) > 0:
		eventType = watcher.ContainerDelete
	case (event.Mask & inotify.InMovedFrom) > 0:
		eventType = watcher.ContainerDelete
	case (event.Mask & inotify.InMovedTo) > 0:
		eventType = watcher.ContainerAdd
	default:
		// Ignore other events.
		return nil
	}

	// Derive the container name from the path name.
	var containerName string
	for _, mount := range w.cgroupPaths {
		mountLocation := path.Clean(mount) + "/"
		if strings.HasPrefix(event.Name, mountLocation) {
			containerName = event.Name[len(mountLocation)-1:]
			break
		}
	}
	if containerName == "" {
		return fmt.Errorf("unable to detect container from watch event on directory %q", event.Name)
	}

	// Maintain the watch for the new or deleted container.
	switch eventType {
	case watcher.ContainerAdd:
		// New container was created, watch it.
		alreadyWatched, err := w.watchDirectory(events, event.Name, containerName)
		if err != nil {
			return err
		}

		// Only report container creation once.
		if alreadyWatched {
			return nil
		}
	case watcher.ContainerDelete:
		// Container was deleted, stop watching for it.
		lastWatched, err := w.watcher.RemoveWatch(containerName, event.Name)
		if err != nil {
			return err
		}

		// Only report container deletion once.
		if !lastWatched {
			return nil
		}
	default:
		return fmt.Errorf("unknown event type %v", eventType)
	}

	// Deliver the event.
	events <- watcher.ContainerEvent{
		EventType:   eventType,
		Name:        containerName,
		WatchSource: watcher.Raw,
	}

	return nil
}
```



### 2.5 containerData

containerData 中包含了一个容器的基本信息 containerInfo 以及操作这个容器的 handler

```go
// 包含容器的基本信息，containerHandler 用于操作 cri 并更新 data 中的信息
type containerData struct {
	oomEvents uint64
	// 与容器交互
	handler container.ContainerHandler
	// 容器的基本信息
	info containerInfo
	// 用于缓存该容器的指标信息
	memoryCache *memory.InMemoryCache
	lock        sync.Mutex
	// 获取容器 load 信息
	loadReader cpuload.CpuLoadReader
	// 获取某个 cgroups 下面容器的某段时间的摘要信息，目前主要是 cpu 以及 memory 信息
	summaryReader *summary.StatsSummary

	loadAvg                  float64 // smoothed load average seen so far.
	loadDAvg                 float64 // smoothed load.d average seen so far.
	housekeepingInterval     time.Duration
	maxHousekeepingInterval  time.Duration
	allowDynamicHousekeeping bool
	infoLastUpdatedTime      time.Time
	statsLastUpdatedTime     time.Time
	lastErrorTime            time.Time
	//  used to track time
	clock clock.Clock

	// Decay value used for load average smoothing. Interval length of 10 seconds is used.
	// 用于负载平均平滑的衰减值。间隔长度为 10s
	loadDecay float64

	// Whether to log the usage of this container when it is updated.
	logUsage bool

	// Tells the container to stop.
	// 告知容器停止 housekeeping
	stop chan struct{}

	// Tells the container to immediately collect stats
	// 告诉容器立即收集统计信息
	onDemandChan chan chan struct{}

	// Runs custom metric collectors.
	// 运行自定义指标收集器
	collectorManager collector.CollectorManager

	// perfCollector updates stats for perf_event cgroup controller.
	perfCollector stats.Collector

	// resctrlCollector updates stats for resctrl controller.
	resctrlCollector stats.Collector
}
```

#### 2.5.1 containerInfo

containerInfo 中的信息很少，因为 cAdvisor 更关注容器的性能，在 k8s 中，cri + cAdvisor  合作才能获取容器的信息以及性能

```go
type containerInfo struct {
	info.ContainerReference
    // 子容器
	Subcontainers []info.ContainerReference
	Spec          info.ContainerSpec
}

// 基本的容器信息
type ContainerReference struct {

	Id string `json:"id,omitempty"`

	Name string `json:"name"`

	Aliases []string `json:"aliases,omitempty"`

	Namespace string `json:"namespace,omitempty"`
}
```

#### 2.5.2 containerHandler

containerHandler 用于操作容器，也提供了获得容器基本信息的功能

```go
// ContainerHandler
type ContainerHandler interface {
	ContainerReference() (info.ContainerReference, error)

	GetSpec() (info.ContainerSpec, error)

	// 获取容器当前状态
	GetStats() (*info.ContainerStats, error)

	// 获取当前容器的子容器
	ListContainers(listType ListType) ([]info.ContainerReference, error)

	// 当前容器的所有进程id
	ListProcesses(listType ListType) ([]int, error)

	// 获取容器指定资源的 cgroup 绝对路径
	GetCgroupPath(resource string) (string, error)

	// 获取容器的标签map
	GetContainerLabels() map[string]string

	// 获取容器的 ip 地址
	GetContainerIPAddress() string

	Exists() bool

	// 释放 ContainerHandler 所使用的资源，如 fds、go routines等
	Cleanup()

	Start()

	Type() ContainerType
}
```

#### 2.5.3 ContainerHandlerFactory

ContainerHandler 是通过工厂模式创建的，ContainerHandlerFactory 是为指定的容器创建关联的 ContainerHandler 对象，cAdvisor 中有多种容器工厂 ：

| 类型       | 处理范围                                                   |
| ---------- | ---------------------------------------------------------- |
| mesos      | 只处理mesos关联容器                                        |
| containerd | 只处理containerd关联容器                                   |
| docker     | /docker 下处于Running状态的容器                            |
| cri-o      | /crio 下的容器                                             |
| systemd    | 处理包含 .mount 后缀的容器                                 |
| raw        | 名字为“/”，或 raw_cgroup_prefix_whitelist 中指定前缀的容器 |

```go
type ContainerHandlerFactory interface {
    // 通过该方法为指定的 container 创建一个 ContainerHandler，用于处理对该 container 的操作。 CanHandleAndAccept() 必须返回 true
    // name：容器名称
    // inHostNamespace：cAdvisor 是否运行在容器中
    NewContainerHandler(name string, inHostNamespace bool) (c ContainerHandler, err error)
    
    // 判断当期的 factory 能否接收并处理指定的容器
    CanHandleAndAccept(name string) (handle bool, accept bool, err error)
    
    // factory 名称
    String() string
    
    // 返回调试信息
    DebugInfo() map[string][]string
}
```

那么 cAdvisor 什么时候才会创建 containerHandler 呢？肯定是检测到环境中有容器新增时，但是 cAdvisor 如何知道系统中新增了容器呢？

也就是上面的使用 INotify 监听 cgroups 的目录变化，出现变化时将事件转为容器的变化事件，由监听器来处理 containerEvent，比如新增 containerHandler

### 2.6 FsHandler

FsHandler 负责定期收集**容器**各文件系统的使用情况。在新增容器并创建 ContainerHandler 时，会为容器创建关联的 FsHandler 实例。

#### 2.6.1 realFsHandler

realFsHandler 是一个通用 FsHandler，用于定期收集并更新容器 rootfs 和 extraDir（/opt/lib/docker/containers/${容器ID} 目录）的文件系统使用情况。

#### 2.6.2 dockerFsHandler

dockerFsHandler 是一个专为 Docker 设计的复合 FsHandler 实现，它包含realFsHandler、devicemapper ThinPoolWatcher 和 zfsWatcher

```go
type dockerFsHandler struct {
    fsHandler common.FsHandler

    // thinPoolWatcher is the devicemapper thin pool watcher
    thinPoolWatcher *devicemapper.ThinPoolWatcher
    // deviceID is the id of the container's fs device
    deviceID string

    // zfsWatcher is the zfs filesystem watcher
    zfsWatcher *zfs.ZfsWatcher
    // zfsFilesystem is the docker zfs filesystem
    zfsFilesystem string
}
```

### 2.7 EventManager

EventManager 管理着机器上发生的容器事件，调用方可以通过调用 WatchEvents() 方法监听自己关心的事件，或调用 AddEvent() 方法新增事件到 EventManager。**用户可以通过调用 HTTP 接口设置要监听的事件，并获取这些事件。**目前已定义的事件包括：

- oom ：通过监听 /dev/kmsg 内核日志，获取容器 OOM 事件
- oomKill ：同上
- containerCreation ：容器新增事件
- containerDeletion ：容器销毁事件

```go
type EventManager interface {
    // 当 WatchEvents() 方法被调用时，就会生成一个新的 watch 对象，并注册到 EventManager 中
    // 该方法会返回一个 EventChannel 通道，监听到的满足条件的事件会被放入该通道中，调用方从该通道中读取事件
    WatchEvents(request *Request) (*EventChannel, error)
    
    // 从 eventStore 中查询满足指定条件的事件列表
    GetEvents(request *Request) ([]*info.Event, error)
    
    // 允许调用方添加一个事件到事件队列中，该方法的执行流程为：
    // 1. 将 event 添加到 eventStore 中
    // 2. 遍历所有的 watch，判断是否满足 watch 条件，如果满足，则放入 watch 的 eventChannel 中，这样对应的调用方就能收到该事件
    AddEvent(e *info.Event) error
    
    // 取消对 watch_id 所要求的事件的监听，从 watchers 中移除 watch 对象，并关闭其 eventChannel
    StopWatch(watch_id int)
}
```

#### 2.7.1 events

events 是 EventManager 的默认实现类 ：

```go
type events struct {
    // 按类型存储各种事件
    eventStore map[info.EventType]*utils.TimedStore
    
    // 所有监听 event 的消费者, 以 watch id 为 key
    // 所有的消费者会被封装为 watch
    watchers map[int]*watch
    
    // lock guarding the eventStore.
    eventsLock sync.RWMutex
    
    // lock guarding watchers.
    watcherLock sync.RWMutex
    
    // 上一个已分配的 watch id，每个 watch 对象都有一个唯一的id。每次有新的 watch 生成时，该值加1
    lastId int
    
    // 事件存储策略
    storagePolicy StoragePolicy
}

type watch struct {
	// 消费者监听的请求
	request *Request
	// 给消费者发送事件的 channel
	eventChannel *EventChannel
}
```

#### 2.7.2 StoragePolicy

StoragePolicy 定义了事件在内存中存储的策略，包括事件存储最大时长（默认24小时）、最大可保存事件数量（默认10w条）、各类型事件事件存储最大时长和最大可保存事件数量。

```go
type StoragePolicy struct {
    // 各类事件默认保留的最大时长
    DefaultMaxAge       time.Duration
  // 各类事件默认保留的最大条数
    DefaultMaxNumEvents int
    // 各类事件保留的最大时长
    PerTypeMaxAge       map[info.EventType]time.Duration
  // 各类事件保留的最大条数
    PerTypeMaxNumEvents map[info.EventType]int
}
```



### 2.8 MemoryStorage

为 cAdvisor 提供存储服务，使用之前需要为其注册驱动，调用 MemoryStorage 存储数据时会遍历所有**驱动**进行存储

```go
type InMemoryCache struct {
	lock              sync.RWMutex
    // 容器数据的缓存
	containerCacheMap map[string]*containerCache
	maxAge            time.Duration
    // 所有驱动
	backend           []storage.StorageDriver
}
```

举例 AddStats ：

```go
func (c *InMemoryCache) AddStats(cInfo *info.ContainerInfo, stats *info.ContainerStats) error {
	var cstore *containerCache
	var ok bool

	func() {
		c.lock.Lock()
		defer c.lock.Unlock()
		if cstore, ok = c.containerCacheMap[cInfo.ContainerReference.Name]; !ok {
			cstore = newContainerStore(cInfo.ContainerReference, c.maxAge)
			c.containerCacheMap[cInfo.ContainerReference.Name] = cstore
		}
	}()
	
    // 遍历所有驱动进行数据的存储
	for _, backend := range c.backend {
		
		if err := backend.AddStats(cInfo, stats); err != nil {
			klog.Error(err)
		}
	}
	return cstore.AddStats(stats)
}
```

**StorageDriver** 用于将数据转存到具体的数据存储服务中，比如 redis、mq。

```go
type StorageDriver interface {
    // 添加指标数据
    AddStats(cInfo *info.ContainerInfo, stats *info.ContainerStats) error

    // 将清除存储驱动程序的状态。存储在底层存储器中的元素可以被删除，
    // 也可以不被删除，这取决于存储驱动程序的实现。
    Close() error
}
```

cAdvisor 支持多种存储驱动 ：es、kafka、redis、influxdb...

### 2.9 Collector







































## 3. cAdvisor

cmd/cAdvisor.go 中启动 cAdvisor 的代码为 main().go，其实也就是 new 一个 manager 然后 start

1. 将需要采集的指标统计一下

   可以通过 --enable_metrics 指定，若未指定则使用默认值

2. 创建 MemoryStorage 提供数据存储服务

   可以通过 --storage_driver 指定驱动名称，默认存在内存里

3. 创建 manager 并启动

4. cAdvisor 提供对外 http 服务，可以通过 http 请求获取 cAdvisor 的监控数据

```go
func init() {
	optstr := container.AllMetrics.String()
	flag.Var(&ignoreMetrics, "disable_metrics", "省略")
	flag.Var(&enableMetrics, "enable_metrics", "省略")
}

func main() {
	klog.InitFlags(nil)
	defer klog.Flush()
	// Default logging verbosity to V(2)
	_ = flag.Set("v", "2")
	flag.Parse()

	if *versionFlag {
		fmt.Printf("cAdvisor version %s (%s)\n", version.Info["version"], version.Info["revision"])
		os.Exit(0)
	}

	// 需要采集的指标
	var includedMetrics container.MetricSet
	if len(enableMetrics) > 0 {
		includedMetrics = enableMetrics
	} else {
        // 如果没有指定，则使用默认值
		includedMetrics = container.AllMetrics.Difference(ignoreMetrics)
	}
	klog.V(1).Infof("enabled metrics: %s", includedMetrics.String())
    // 设置最大协程数量
	setMaxProcs()

	// 存储方式
	memoryStorage, err := NewMemoryStorage()
	if err != nil {
		klog.Fatalf("Failed to initialize storage driver: %s", err)
	}

	// sysFs 用于获取操作系统底层的一些信息，cpu memory block
	sysFs := sysfs.NewRealSysFs()

	// 采集器的 http 客户端
	collectorHTTPClient := createCollectorHTTPClient(*collectorCert, *collectorKey)

	// 创建 manager
	resourceManager, err := manager.New(memoryStorage, sysFs, manager.HousekeepingConfigFlags, includedMetrics, &collectorHTTPClient, strings.Split(*rawCgroupPrefixWhiteList, ","), strings.Split(*envMetadataWhiteList, ","), *perfEvents, *resctrlInterval)
	if err != nil {
		klog.Fatalf("Failed to create a manager: %s", err)
	}

	mux := http.NewServeMux()

	if *enableProfiling {
		mux.HandleFunc("/debug/pprof/", pprof.Index)
		mux.HandleFunc("/debug/pprof/cmdline", pprof.Cmdline)
		mux.HandleFunc("/debug/pprof/profile", pprof.Profile)
		mux.HandleFunc("/debug/pprof/symbol", pprof.Symbol)
	}

	// Register all HTTP handlers.
	// 对外提供 http 服务
	err = cadvisorhttp.RegisterHandlers(mux, resourceManager, *httpAuthFile, *httpAuthRealm, *httpDigestFile, *httpDigestRealm, *urlBasePrefix)
	if err != nil {
		klog.Fatalf("Failed to register HTTP handlers: %v", err)
	}

	containerLabelFunc := metrics.DefaultContainerLabels
	if !*storeContainerLabels {
		whitelistedLabels := strings.Split(*whitelistedContainerLabels, ",")
		// Trim spacing in labels
		for i := range whitelistedLabels {
			whitelistedLabels[i] = strings.TrimSpace(whitelistedLabels[i])
		}
		containerLabelFunc = metrics.BaseContainerLabels(whitelistedLabels)
	}

	// Register Prometheus collector to gather information about containers, Go runtime, processes, and machine
	cadvisorhttp.RegisterPrometheusHandler(mux, resourceManager, *prometheusEndpoint, containerLabelFunc, includedMetrics)

	// Start the manager.
	// 启动 manager
	if err := resourceManager.Start(); err != nil {
		klog.Fatalf("Failed to start manager: %v", err)
	}

	// Install signal handler.
	// 进程被 kill 时调用 manager.stop
	installSignalHandler(resourceManager)

	klog.V(1).Infof("Starting cAdvisor version: %s-%s on port %d", version.Info["version"], version.Info["revision"], *argPort)

	rootMux := http.NewServeMux()
	rootMux.Handle(*urlBasePrefix+"/", http.StripPrefix(*urlBasePrefix, mux))

	addr := fmt.Sprintf("%s:%d", *argIP, *argPort)
	klog.Fatal(http.ListenAndServe(addr, rootMux))
}
```

### 3.1 NewMemoryStorage

NewMemoryStorage 创建数据服务，将数据存储在驱动中

```go
var (
	storageDriver   = flag.String("storage_driver", "", fmt.Sprintf("Storage `driver` to use. Data is always cached shortly in memory, this controls where data is pushed besides the local cache. Empty means none, multiple separated by commas. Options are: <empty>, %s", strings.Join(storage.ListDrivers(), ", ")))
	storageDuration = flag.Duration("storage_duration", 2*time.Minute, "How long to keep data stored (Default: 2min).")
)

// NewMemoryStorage creates a memory storage with an optional backend storage option.
// 先创建 driver，通过 driver 创建 memory.InMemoryCache.
// 一个 memory.InMemoryCache 可以有多个驱动，比如可以存储在内存、普罗米修斯中
func NewMemoryStorage() (*memory.InMemoryCache, error) {
    // 1. 创建驱动
    backendStorages := []storage.StorageDriver{}
    // 通过命令行指定驱动名称，使用 , 隔开
    for _, driver := range strings.Split(*storageDriver, ",") {
       if driver == "" {
          continue
       }
       storage, err := storage.New(driver)
       if err != nil {
          return nil, err
       }
       backendStorages = append(backendStorages, storage)
       klog.V(1).Infof("Using backend storage type %q", driver)
    }
    klog.V(1).Infof("Caching stats in memory for %v", *storageDuration)
    // 创建 memory.InMemoryCache，一个 memory.InMemoryCache 可以有多个驱动
    return memory.New(*storageDuration, backendStorages), nil
}
```





### 3.2 createCollectorHTTPClient

```go
var collectorCert = flag.String("collector_cert", "", "Collector's certificate, exposed to endpoints for certificate based authentication.")
var collectorKey = flag.String("collector_key", "", "Key for the collector's certificate")

// 创建采集器客户端
func createCollectorHTTPClient(collectorCert, collectorKey string) http.Client {
	//Enable accessing insecure endpoints. We should be able to access metrics from any endpoint
	tlsConfig := &tls.Config{
		InsecureSkipVerify: true,
	}

	if collectorCert != "" {
		if collectorKey == "" {
			klog.Fatal("The collector_key value must be specified if the collector_cert value is set.")
		}
		cert, err := tls.LoadX509KeyPair(collectorCert, collectorKey)
		if err != nil {
			klog.Fatalf("Failed to use the collector certificate and key: %s", err)
		}

		tlsConfig.Certificates = []tls.Certificate{cert}
		tlsConfig.BuildNameToCertificate() //nolint: staticcheck
	}

	transport := &http.Transport{
		TLSClientConfig: tlsConfig,
	}

	return http.Client{Transport: transport}
}
```

### 3.3 manager.New

```go
// New takes a memory storage and returns a new manager.
func New(memoryCache *memory.InMemoryCache, sysfs sysfs.SysFs, HousekeepingConfig HousekeepingConfig, includedMetricsSet container.MetricSet, collectorHTTPClient *http.Client, rawContainerCgroupPathPrefixWhiteList, containerEnvMetadataWhiteList []string, perfEventsFile string, resctrlInterval time.Duration) (Manager, error) {
	if memoryCache == nil {
		return nil, fmt.Errorf("manager requires memory storage")
	}

	// Detect the container we are running on.
	// cgroups v2 的所有控制器都在同一目录中，所以可以直接使用 /
	// 但是 v1 版本的不同子系统在不同的目录下，所以需要通过 api 获取具体挂载在哪
	selfContainer := "/"
	var err error
	// Avoid using GetOwnCgroupPath on cgroup v2 as it is not supported by libcontainer
	// 如果系统使用的是 cgroup v2，避免使用 GetOwnCgroup，因为 libcontainer 不支持这个 api
	if !cgroups.IsCgroup2UnifiedMode() {
		selfContainer, err = cgroups.GetOwnCgroup("cpu")
		if err != nil {
			return nil, err
		}
		klog.V(2).Infof("cAdvisor running in container: %q", selfContainer)
	}

	context := fs.Context{}

	if err := container.InitializeFSContext(&context); err != nil {
		return nil, err
	}

	fsInfo, err := fs.NewFsInfo(context)
	if err != nil {
		return nil, err
	}

	// If cAdvisor was started with host's rootfs mounted, assume that its running
	// in its own namespaces.
	inHostNamespace := false
	if _, err := os.Stat("/rootfs/proc"); os.IsNotExist(err) {
		inHostNamespace = true
	}

	// Register for new subcontainers.
	eventsChannel := make(chan watcher.ContainerEvent, 16)

	newManager := &manager{
		containers:                            make(map[namespacedContainerName]*containerData),
		quitChannels:                          make([]chan error, 0, 2),
		memoryCache:                           memoryCache,
		fsInfo:                                fsInfo,
		sysFs:                                 sysfs,
		cadvisorContainer:                     selfContainer,
		inHostNamespace:                       inHostNamespace,
		startupTime:                           time.Now(),
		maxHousekeepingInterval:               *HousekeepingConfig.Interval,
		allowDynamicHousekeeping:              *HousekeepingConfig.AllowDynamic,
		includedMetrics:                       includedMetricsSet,
		containerWatchers:                     []watcher.ContainerWatcher{},
		eventsChannel:                         eventsChannel,
		collectorHTTPClient:                   collectorHTTPClient,
		rawContainerCgroupPathPrefixWhiteList: rawContainerCgroupPathPrefixWhiteList,
		containerEnvMetadataWhiteList:         containerEnvMetadataWhiteList,
	}

	// 先获取一下 machineInfo
	machineInfo, err := machine.Info(sysfs, fsInfo, inHostNamespace)
	if err != nil {
		return nil, err
	}
	newManager.machineInfo = *machineInfo
	klog.V(1).Infof("Machine: %+v", newManager.machineInfo)

	newManager.perfManager, err = perf.NewManager(perfEventsFile, machineInfo.Topology)
	if err != nil {
		return nil, err
	}

	newManager.resctrlManager, err = resctrl.NewManager(resctrlInterval, resctrl.Setup, machineInfo.CPUVendorID, inHostNamespace)
	if err != nil {
		klog.V(4).Infof("Cannot gather resctrl metrics: %v", err)
	}

	versionInfo, err := getVersionInfo()
	if err != nil {
		return nil, err
	}
	klog.V(1).Infof("Version: %+v", *versionInfo)

	// 事件处理器
	newManager.eventHandler = events.NewEventManager(parseEventsStoragePolicy())
	return newManager, nil
}
```





### 3.4 manager.Start

启动 manager，主要是注册容器监听器，由于有不同种类的容器，所以要通过插件的形式注册

```go
// Start the container manager.
func (m *manager) Start() error {
	// 注册容器监听器，可以监听不同 runtime 的容器，比如 docker、podman
	m.containerWatchers = container.InitializePlugins(m, m.fsInfo, m.includedMetrics)

    // 监听 cgroup 的事件监听器(INotify)
	err := raw.Register(m, m.fsInfo, m.includedMetrics, m.rawContainerCgroupPathPrefixWhiteList)
	if err != nil {
		klog.Errorf("Registration of the raw container factory failed: %v", err)
	}

    // 监听容器的监听器
	rawWatcher, err := raw.NewRawContainerWatcher(m.includedMetrics)
	if err != nil {
		return err
	}
	m.containerWatchers = append(m.containerWatchers, rawWatcher)

	// Watch for OOMs.
	err = m.watchForNewOoms()
	if err != nil {
		klog.Warningf("Could not configure a source for OOM detection, disabling OOM events: %v", err)
	}

	// If there are no factories, don't start any housekeeping and serve the information we do have.
	if !container.HasFactories() {
		return nil
	}

	// Create root and then recover all containers.
	err = m.createContainer("/", watcher.Raw)
	if err != nil {
		return err
	}
	klog.V(2).Infof("Starting recovery of all containers")
	err = m.detectSubcontainers("/")
	if err != nil {
		return err
	}
	klog.V(2).Infof("Recovery completed")

	// Watch for new container.
	quitWatcher := make(chan error)
	err = m.watchForNewContainers(quitWatcher)
	if err != nil {
		return err
	}
	m.quitChannels = append(m.quitChannels, quitWatcher)

	// Look for new containers in the main housekeeping thread.
	quitGlobalHousekeeping := make(chan error)
	m.quitChannels = append(m.quitChannels, quitGlobalHousekeeping)
	go m.globalHousekeeping(quitGlobalHousekeeping)

	quitUpdateMachineInfo := make(chan error)
	m.quitChannels = append(m.quitChannels, quitUpdateMachineInfo)
	go m.updateMachineInfo(quitUpdateMachineInfo)

	return nil
}
```

